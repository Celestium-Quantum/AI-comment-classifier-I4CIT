{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9300356,"sourceType":"datasetVersion","datasetId":5631196}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/salilapte/data-mining-comment-classifier?scriptVersionId=212047758\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    roc_auc_score,\n    classification_report\n)\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/ai-human/AI_Human.csv')\n\n# Total entries\nprint(df.count().sum())\n\n# A brief overview\ndf.describe()\n\n# Check for missing values\nmissing_values = df.isnull().sum()\nprint(\"Missing Values:\\n\", missing_values)\n\n# Class distribution in 'generated' column\nclass_distribution = df['generated'].value_counts()\nprint(\"\\nClass Distribution:\\n\", class_distribution)\n\n# Text length analysis\ndf['text_length'] = df['text'].apply(len)\n# Summary statistics for text length\ntext_length_stats = df['text_length'].describe()\nprint(\"\\nText Length Statistics:\\n\", text_length_stats)\n\n# Function to clean text without NLTK\ndef clean_text_no_nltk(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove special characters, numbers, and punctuation\n    text = re.sub(r'[^a-z\\s]', '', text)\n    # Tokenize and remove simple stopwords manually\n    stop_words = {'the', 'and', 'is', 'in', 'to', 'of', 'for', 'it', 'on', 'this', 'that', 'with', 'a', 'as'}\n    tokens = text.split()\n    tokens = [word for word in tokens if word not in stop_words]\n    # Join tokens back into a cleaned string\n    cleaned_text = ' '.join(tokens)\n    return cleaned_text\n\n# Apply the cleaning function to the 'text' column\ndf['cleaned_text'] = df['text'].apply(clean_text_no_nltk)\n\n# Display the first few rows to verify cleaning\nprint(df[['text', 'cleaned_text']].head())\n\n# Text length features\ndf['text_length'] = df['cleaned_text'].apply(len)\ndf['word_count'] = df['cleaned_text'].apply(lambda x: len(x.split()))\ndf['avg_word_length'] = df['cleaned_text'].apply(lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0)\n\n# Display the new features\nprint(df[['text_length', 'word_count', 'avg_word_length']].head())\n\n# Plot histograms for each feature\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\ndf['text_length'].hist(bins=30, color='skyblue')\nplt.title('Text Length Distribution')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 3, 2)\ndf['word_count'].hist(bins=30, color='lightgreen')\nplt.title('Word Count Distribution')\nplt.xlabel('Word Count')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 3, 3)\ndf['avg_word_length'].hist(bins=30, color='lightcoral')\nplt.title('Average Word Length Distribution')\nplt.xlabel('Avg Word Length')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n# Extracting unigrams and bigrams using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=500)\ntfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n\n# Convert the TF-IDF matrix to a DataFrame for easier interpretation\ntfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Display the top features (unigrams and bigrams)\nprint(\"\\nTF-IDF Features (Unigrams and Bigrams):\\n\", tfidf_df.head())\n\n# Compute the average TF-IDF score for each feature\ntfidf_mean = tfidf_df.mean().sort_values(ascending=False)\n\n# Select the top 20 features\ntop_features = tfidf_mean.head(20)\n\n# Plot the top features\nplt.figure(figsize=(10, 6))\ntop_features.plot(kind='bar', color='skyblue')\nplt.title('Top 20 TF-IDF Features (Unigrams and Bigrams)')\nplt.ylabel('Average TF-IDF Score')\nplt.xlabel('Features')\nplt.xticks(rotation=45, ha='right')\nplt.show()\n\n# Vectorize text data\nvectorizer = TfidfVectorizer(max_features=5000)  # Reduce features for efficiency\nX = vectorizer.fit_transform(df['text'])\ny = df['generated']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Logistic Regression\nlog_model = LogisticRegression(max_iter=1000, solver='liblinear')  # Ensure solver compatibility\nlog_model.fit(X_train, y_train)\n\n# Predictions and evaluation\ny_pred = log_model.predict(X_test)\ny_score = log_model.decision_function(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Logistic Regression Accuracy: {accuracy}\")\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))\n\n# **Visualization 1: Confusion Matrix**\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Human', 'AI'], yticklabels=['Human', 'AI'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()\n\n# **Visualization 2: ROC Curve**\nfpr, tpr, _ = roc_curve(y_test, y_score)\nroc_auc = auc(fpr, tpr)\nplt.figure(figsize=(6, 4))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.title('ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# **Visualization 3: Precision-Recall Curve**\nprecision, recall, _ = precision_recall_curve(y_test, y_score)\nplt.figure(figsize=(6, 4))\nplt.plot(recall, precision, marker='.', label='Precision-Recall')\nplt.fill_between(recall, precision, alpha=0.3, color='blue')\nplt.title('Precision-Recall Curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.show()\n\n# **Visualization 4: Top Positive and Negative Features**\n# Extract feature coefficients\nfeature_names = vectorizer.get_feature_names_out()\ncoefficients = log_model.coef_[0]\n\n# Combine features and coefficients into a DataFrame\ncoef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\ntop_positive = coef_df.nlargest(10, 'Coefficient')\ntop_negative = coef_df.nsmallest(10, 'Coefficient')\n\n# Plot top positive coefficients\nplt.figure(figsize=(8, 5))\nsns.barplot(x='Coefficient', y='Feature', data=top_positive, palette='Greens', hue=None, legend=False)\nplt.title('Top 10 Positive Features (AI Indicating Words)')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.show()\n\n# Plot top negative coefficients\nplt.figure(figsize=(8, 5))\nsns.barplot(x='Coefficient', y='Feature', data=top_negative, palette='Reds', hue=None, legend=False)\nplt.title('Top 10 Negative Features (Human Indicating Words)')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.show()\n\n# **Visualization 5: Histogram of Predictions**\nplt.figure(figsize=(6, 4))\nsns.histplot(y_score, kde=True, bins=30, color='purple')\nplt.axvline(0, color='red', linestyle='--', label='Decision Boundary')\nplt.title('Histogram of Decision Function Scores')\nplt.xlabel('Decision Score')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T03:52:41.771457Z","iopub.execute_input":"2024-12-09T03:52:41.77201Z","iopub.status.idle":"2024-12-09T04:04:35.819697Z","shell.execute_reply.started":"2024-12-09T03:52:41.77196Z","shell.execute_reply":"2024-12-09T04:04:35.818485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize K-Fold Cross-Validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Initialize Logistic Regression model\nmodel = LogisticRegression(max_iter=1000, solver='liblinear')\n\n# Lists to store performance metrics\naccuracies = []\nprecisions = []\nrecalls = []\nroc_aucs = []\n\nprint(\"Performing K-Fold Cross-Validation...\")\n\n# Perform K-Fold Cross-Validation\nfor fold, (train_index, test_index) in enumerate(kf.split(X)):\n    print(f\"Fold {fold + 1}\")\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Predict on the test set\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for ROC AUC\n    \n    # Evaluate metrics\n    acc = accuracy_score(y_test, y_pred)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    roc_auc = roc_auc_score(y_test, y_proba)\n    \n    # Store metrics\n    accuracies.append(acc)\n    precisions.append(prec)\n    recalls.append(rec)\n    roc_aucs.append(roc_auc)\n    \n    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, ROC AUC: {roc_auc:.4f}\")\n    print(\"-\" * 50)\n\n# Print average metrics\nprint(\"\\nK-Fold Cross-Validation Results:\")\nprint(f\"Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\nprint(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\nprint(f\"Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\nprint(f\"ROC AUC: {np.mean(roc_aucs):.4f} ± {np.std(roc_aucs):.4f}\")\n\n# Train the final model on the entire dataset (if needed)\nmodel.fit(X, y)\nprint(\"\\nFinal Model Trained on Full Dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T04:04:35.822037Z","iopub.execute_input":"2024-12-09T04:04:35.82252Z","iopub.status.idle":"2024-12-09T04:07:32.622421Z","shell.execute_reply.started":"2024-12-09T04:04:35.82247Z","shell.execute_reply":"2024-12-09T04:07:32.621007Z"}},"outputs":[],"execution_count":null}]}